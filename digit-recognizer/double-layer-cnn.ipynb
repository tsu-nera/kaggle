{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer using Double Layer CNN\n",
    "* https://www.kaggle.com/c/digit-recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepareing data\n",
    "Download data from https://www.kaggle.com/c/digit-recognizer/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "validation_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/digit-recognizer/train.csv')\n",
    "test  = pd.read_csv('../input/digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "split train data to labels and pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = (train.ix[:,1:].values).astype('float32')\n",
    "labels = pd.get_dummies(train.ix[:,0]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(42000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into training & validation\n",
    "valid_features = features[:validation_size]\n",
    "valid_labels = labels[:validation_size]\n",
    "\n",
    "train_features = features[validation_size:]\n",
    "train_labels = labels[validation_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 784)\n",
      "(40000, 10)\n",
      "(2000, 784)\n",
      "(2000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(valid_features.shape)\n",
    "print(valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = (test.values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a TensorFlow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a first convolultion layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_filters1 = 32\n",
    "\n",
    "x_image = tf.reshape(features, [-1,28,28,1])\n",
    "\n",
    "W_conv1 = tf.Variable(tf.truncated_normal([5,5,1,num_filters1], stddev=0.1))\n",
    "h_conv1 = tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[num_filters1]))\n",
    "h_conv1_cutoff = tf.nn.relu(h_conv1 + b_conv1)\n",
    "h_pool1 = tf.nn.max_pool(h_conv1_cutoff, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a second convolution layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_filters2 = 64\n",
    "\n",
    "W_conv2 = tf.Variable(tf.truncated_normal([5,5,num_filters1,num_filters2], stddev=0.1))\n",
    "h_conv2 = tf.nn.conv2d(h_pool1, W_conv2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "b_conv2 = tf.Variable(tf.constant(0.1, shape=[num_filters2]))\n",
    "h_conv2_cutoff = tf.nn.relu(h_conv2 + b_conv2)\n",
    "h_pool2 = tf.nn.max_pool(h_conv2_cutoff, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make fully-connected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_units1 = 7*7*num_filters2\n",
    "num_units2 = 1024\n",
    "\n",
    "h_pool_flat = tf.reshape(h_pool2, [-1,num_units1])\n",
    "\n",
    "# Weights & bias\n",
    "w1 = tf.Variable(tf.random_normal([num_units1, num_units2]))\n",
    "b1 = tf.Variable(tf.random_normal([num_units2]))\n",
    "\n",
    "# Hidden Layer - a(xW1 + b1)\n",
    "z1 = tf.add(tf.matmul(h_pool_flat, w1), b1)\n",
    "h1 = tf.nn.relu(z1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h1_drop = tf.nn.dropout(h1, keep_prob)\n",
    "\n",
    "# Weights & bias\n",
    "w0 = tf.Variable(tf.random_normal([num_units2, n_classes]))\n",
    "b0 = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - h1W0 + b0\n",
    "logits = tf.add(tf.matmul(h1_drop, w0), b0)\n",
    "\n",
    "# Define loss and optimizer\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "predict = tf.argmax(logits, 1)\n",
    "correct_prediction = tf.equal(predict, tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_epoch_stats(epoch_i, sess, last_features, last_labels, prob):\n",
    "    \"\"\"\n",
    "    Print cost and validation accuracy of an epoch\n",
    "    \"\"\"\n",
    "    current_cost = sess.run(\n",
    "        cost,\n",
    "        feed_dict={features: last_features, labels: last_labels, keep_prob: prob})\n",
    "    valid_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: valid_features, labels: valid_labels, keep_prob: prob})\n",
    "    print('Epoch: {:<4} - Cost: {:<8.3} Valid Accuracy: {:<5.3}'.format(\n",
    "        epoch_i,\n",
    "        current_cost,\n",
    "        valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    outout_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        outout_batches.append(batch)\n",
    "        \n",
    "    return outout_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "epochs = 10\n",
    "learn_rate = 0.0001\n",
    "prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batches = batches(batch_size, train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0    - Cost: 3.82e+03 Valid Accuracy: 0.624\n",
      "Epoch: 1    - Cost: 1.44e+03 Valid Accuracy: 0.711\n",
      "Epoch: 2    - Cost: 1.31e+03 Valid Accuracy: 0.738\n",
      "Epoch: 3    - Cost: 6.15e+02 Valid Accuracy: 0.787\n",
      "Epoch: 4    - Cost: 3.91e+02 Valid Accuracy: 0.812\n",
      "Epoch: 5    - Cost: 3.98e+02 Valid Accuracy: 0.816\n",
      "Epoch: 6    - Cost: 69.6     Valid Accuracy: 0.811\n",
      "Epoch: 7    - Cost: 2.23e+02 Valid Accuracy: 0.84 \n",
      "Epoch: 8    - Cost: 2.2e+02  Valid Accuracy: 0.842\n",
      "Epoch: 9    - Cost: 66.2     Valid Accuracy: 0.867\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch_i in range(epochs):\n",
    "\n",
    "        # Loop over all batches\n",
    "        for batch_features, batch_labels in train_batches:\n",
    "            train_feed_dict = {\n",
    "                features: batch_features,\n",
    "                labels: batch_labels,\n",
    "                learning_rate: learn_rate,\n",
    "                keep_prob: prob}\n",
    "            sess.run(optimizer, feed_dict=train_feed_dict)\n",
    "\n",
    "        # Print cost and validation accuracy of an epoch\n",
    "        print_epoch_stats(epoch_i, sess, batch_features, batch_labels, prob)\n",
    "\n",
    "    predictions = sess.run(\n",
    "                        predict, \n",
    "                        feed_dict={features: test_features,\n",
    "                                   keep_prob: prob})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissions = pd.DataFrame({\"ImageId\": list(range(1, len(predictions)+1)),\n",
    "                             \"Label\": predictions})\n",
    "submissions.to_csv(\"output.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "57px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
